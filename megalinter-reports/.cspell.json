{
    "ignorePaths": [
        "**/node_modules/**",
        "**/vscode-extension/**",
        "**/.git/**",
        "**/.pnpm-lock.json",
        ".vscode",
        "package-lock.json",
        "megalinter-reports"
    ],
    "language": "en",
    "version": "0.2",
    "words": [
        "Checkin)       -- checkin = item[\"lastCheckin\"].strip(",
        "Datacenter",
        "EOOPTS",
        "Faild",
        "GSSAPI",
        "Hyperv)     -- class SetHyperv(FeatureSettings",
        "Hyperv)     -- self.hyperv = SetHyperv(",
        "Hyperv)     -- super(SetHyperv, self",
        "Jresult)       -- def beaker_Jresult(self, jobs",
        "Jresult)       -- passed = self.beaker_Jresult(jobs",
        "Jresult)    -- results = provision.beaker_Jresult({job_name: job_id}",
        "Jstatus)       -- def beaker_Jstatus(self, jobs",
        "Jstatus)       -- while self.beaker_Jstatus(jobs",
        "Jstatus)    -- while provision.beaker_Jstatus({job_name: job_id}",
        "Jsubmit",
        "KUBECONFIG",
        "KUBEVIRT",
        "Kubevirt)   -- class SetKubevirt(FeatureSettings",
        "Kubevirt)   -- self.kubevirt = SetKubevirt(",
        "Kubevirt)   -- super(SetKubevirt, self",
        "Kubvirt",
        "Msvm",
        "Nmap",
        "Nutanix",
        "OPTARG",
        "OPTARG)      -- b",
        "POLARION",
        "POLARION)   -- get_exported_param(\"POLARION_REPORT\"",
        "Polarion)   -- class SetPolarion(FeatureSettings",
        "Polarion)   -- self.polarion = SetPolarion(",
        "Polarion)   -- super(SetPolarion, self",
        "RHELSS",
        "RHEV)       -- get_exported_param(\"RHEV_ISO\"",
        "RHEVM",
        "RHEVM)      -- class SetRHEVM(FeatureSettings",
        "RHEVM)      -- self.rhevm = SetRHEVM(",
        "RHEVM)      -- super(SetRHEVM, self",
        "RHSS",
        "Retcode",
        "SUBMAN",
        "Sapce",
        "Stackable",
        "Successed",
        "TESTRUN",
        "Unlimitted",
        "Unlimitted) -- status is '0 out of Unlimitted'\"",
        "Unsupport",
        "VDSM",
        "VDSM)       -- class SetVDSM(FeatureSettings",
        "VDSM)       -- self.vdsm = SetVDSM(",
        "VDSM)       -- super(SetVDSM, self",
        "VIRT",
        "VIRTWHO",
        "VIRTWHO)       -- get_exported_param(\"VIRTWHO_BUILD\"",
        "VIRTWHO)      -- get_exported_param(\"VIRTWHO_UPSTREAM\"",
        "VIRTWHO)    -- Run virt-who with \"VIRTWHO_DEBUG=0\"'",
        "VIRTWHO)    -- Run virt-who with \"VIRTWHO_DEBUG=1\"'",
        "VIRTWHO)    -- Run virt-who with \"VIRTWHO_ONE_SHOT=0\"'",
        "VIRTWHO)    -- Run virt-who with \"VIRTWHO_ONE_SHOT=1\"'",
        "VIRTWHO)    -- get_exported_param(\"VIRTWHO_BREW_PACKAGE\"",
        "VIRTWHO)    -- get_exported_param(\"VIRTWHO_HOST_IP\"",
        "VIRTWHO)    -- get_exported_param(\"VIRTWHO_HOST_PASSWD\"",
        "VIRTWHO)    -- get_exported_param(\"VIRTWHO_HOST_USER\"",
        "VIRTWHO)    -- get_exported_param(\"VIRTWHO_UPSTREAM\"",
        "VIRTWHO)    -- info(\">>>step1: disable VIRTWHO_INTERVAL option\"",
        "Virt",
        "Virt)       -- super(VirtWhoSCATestCase, cls",
        "Virtwho",
        "Virtwho)    -- class ConfigureVirtwho(FeatureSettings",
        "Virtwho)    -- self.virtwho = ConfigureVirtwho(",
        "Virtwho)    -- super(ConfigureVirtwho, self",
        "WONTFIX",
        "WONTFIX)     -- due to Bug 1638182 WONTFIX'",
        "aarch",
        "acpi",
        "activaiton",
        "activationkey",
        "ascci)      -- cannot be set to no-ascci\"",
        "autoconnect",
        "autopart",
        "avaialbe",
        "baseos",
        "bootif",
        "bootloader",
        "bootproto",
        "buildinfo",
        "bymac",
        "bymac)         -- ip = self.get_ipaddr_bymac(mac_addr, ssh_xen",
        "caseid",
        "caseid)        -- def polarion_caseid_mapping(xml_file",
        "caseid)        -- polarion_caseid_mapping(xml_file",
        "cdate",
        "cdate)      -- if [[ $(date +%s -d \"$cdate $ctime\"",
        "celerybeat",
        "checkin",
        "chkconfig",
        "cimv",
        "classpath",
        "clearpart",
        "commandline",
        "composeid",
        "condrestart",
        "cpio",
        "cputype",
        "cputype)       -- rhevm_shell, cluster, cputype",
        "cputype)    -- reader.get(\"rhevm\", \"cputype\"",
        "cracklib",
        "datacenter",
        "datacenter)    -- rhevm_shell, ssh_vdsm, datacenter, storage",
        "datacenter) -- reader.get(\"rhevm\", \"datacenter\"",
        "datalines",
        "dbus",
        "dconf",
        "devel",
        "differernt",
        "disabel",
        "distro",
        "distro)        -- type, variant, arch, distro, job_name",
        "dockerenv",
        "dogfood",
        "dominfo",
        "domstate",
        "domuuid",
        "dumpxml",
        "dumpxml)                 -- libvirt, desc=\"virsh dumpxml for mac\"",
        "editenv",
        "encryped",
        "entilement",
        "epel",
        "epel)         -- self.rhel_epel_repo(ssh_host",
        "epel)       -- # self.install_epel_packages(ssh_rhev",
        "epel)       -- reader.get(\"repo\", \"epel\"",
        "erroronfail",
        "esxi",
        "executabe",
        "exlude",
        "febootstrap",
        "filespath",
        "filespath)  -- os.path.join(root, filespath",
        "firewalld",
        "fomat)         -- write_file(xml_file, fomatTree(rootNode)",
        "fomat)      -- def fomatTree(elem",
        "fomat)      -- return fomatTree(node",
        "fomat)      -- write_file(xmlFile, fomatTree(node)",
        "gconv",
        "getframe)   -- func_name = sys._getframe(",
        "gfxpayload",
        "gpgcheck",
        "groupinstall",
        "guestids",
        "guestuuid)  -- cls.get_hypervisor_guestuuid(cls()",
        "guestuuid)  -- def get_hypervisor_guestuuid(self, uid=None",
        "guestuuid)  -- self.get_hypervisor_guestuuid(",
        "guestuuid)  -- self.get_hypervisor_guestuuid(uid=\"01\"",
        "guestuuid)  -- self.get_hypervisor_guestuuid(uid=\"02\"",
        "gwmi",
        "gzio",
        "hiddenmenu",
        "hostid",
        "hostrequire",
        "hostuuid",
        "hostuuid)      -- re.findall(\".*%s.*\" % hostuuid, name_list, re.I",
        "hostuuid)   -- cls.get_hypervisor_hostuuid(cls()",
        "hostuuid)   -- def get_hypervisor_hostuuid(self, uid=None",
        "hostuuid)   -- self.get_hypervisor_hostuuid(",
        "hostuuid)   -- self.get_hypervisor_hostuuid(uid",
        "hostuuid)   -- self.get_hypervisor_hostuuid(uid=\"01\"",
        "hostuuid)   -- self.get_hypervisor_hostuuid(uid=\"02\"",
        "hwuuid",
        "hwuuid)        -- host_hwuuid.lower(",
        "hwuuid)        -- hwuuid = line.split(\":\"",
        "hwuuid)        -- hwuuid: {0}\".format(hwuuid)",
        "hwuuid)     -- (.*?)'\".format(host_hwuuid",
        "hwuuid)     -- 1}:{0}\".format(host_hwuuid, domain_id)",
        "hwuuid)     -- cls.get_hypervisor_hwuuid(cls()",
        "hwuuid)     -- def get_hypervisor_hwuuid(self, uid=None",
        "hwuuid)     -- self.get_hypervisor_hwuuid(",
        "hyperivosr) -- connect virt-who host from hyperivosr again\"",
        "hyperivosr) -- disconnect virt-who host from hyperivosr\"",
        "hyperivosr) -- is disconnected from hyperivosr by timeout\"",
        "hyperivosr) -- who host can access hyperivosr by default\"",
        "hyperivosr) -- who is connected to hyperivosr normally\"",
        "hyperivsor) -- >>>step3: check the hyperivsor facts\"",
        "hyperv",
        "hyperv)     -- ('libvirt-remote', 'hyperv', 'kubevirt'",
        "hyperv)     -- , \"libvirt-local\", \"hyperv\", \"esx\"",
        "hyperv)     -- def setup_hyperv(",
        "hyperv)     -- in (\"rhevm\", \"xen\", \"hyperv\"",
        "hyperv)     -- reader.get(\"stage\", \"hyperv_user\"",
        "hyperv)     -- remote_modes.append(\"hyperv\"",
        "ifname",
        "ignoremissing",
        "imgbase",
        "impoerter)  -- info(\"Usage: polarion_impoerter.py 1.xml 2.xml\"",
        "initdb",
        "initlabel",
        "insmod",
        "installroot",
        "insteaded",
        "intellij",
        "ipaddr",
        "ipaddr)     -- def get_ipaddr(self, ssh",
        "ipaddr)     -- ipaddr = self.get_ipaddr(ssh",
        "ipaddr)     -- ping_is_connected(self, ipaddr",
        "isautomated",
        "iscreated",
        "isolinux",
        "isregister",
        "isregister) -- self.system_isregister(self.ssh_host(",
        "jdbc",
        "jenkinks",
        "jenkinsjobs",
        "katello",
        "katello)       -- Succeeded to get satellite katello_id: {0}({1}",
        "katello)       -- ssh_sat, desc=\"install katello-ca\"",
        "katello)    -- reader.get(\"satellite\", \"katello_proxy_url\"",
        "keygen",
        "keyscan",
        "keytab",
        "keytab)     -- reader.get(\"beaker\", \"keytab\"",
        "kinit",
        "kinit)         -- def beaker_kinit(self",
        "kinit)         -- desc=\"beaker client kinit\"",
        "kinit)      -- if self.beaker_kinit(",
        "ksdevice",
        "kubeconfig",
        "kubeconfig) -- append(\"(step1,2) No kubeconfig option for cli\"",
        "kubeconfig) -- append(\"(step1,2,3,4) No kubeconfig option for cli\"",
        "kubeconfig) -- hypervisor_config_file\", kubeconfig",
        "kubeconfig) -- notes.append(\"(step1) No kubeconfig option for cli\"",
        "kubeversion",
        "kubevirt",
        "kubevirt)   -- def setup_kubevirt(",
        "kubevirt)   -- hypervisor_type in (\"kubevirt\", \"ahv\"",
        "kubevirt)   -- libvirt-local\", \"vdsm\", \"kubevirt\"",
        "kubevirt)   -- reader.get(\"stage\", \"kubevirt_passwd\"",
        "kubevirt)   -- reader.get(\"stage\", \"kubevirt_user\"",
        "kubevirt)   -- remote', 'hyperv', 'kubevirt'",
        "kubevirt)   -- remote', 'xen', 'rhevm', 'kubevirt'",
        "kubevirt)   -- remote_modes.append(\"kubevirt\"",
        "kubvirt)       -- system_init(\"ci-guest-kubvirt\", ssh_guest",
        "kubvirt)    -- system_init(\"ci-guest-kubvirt\", ssh_guest",
        "langpacks",
        "ldconfig",
        "lein",
        "levelname)  -- fmt=\"%(asctime)s [%(levelname)s] %(message",
        "libexec",
        "libguestfs",
        "libirt",
        "libvirtd",
        "libvirtd)                -- libvirt, desc=\"restart libvirtd service\"",
        "libvirtd)   -- config, and restart libvirtd service\"",
        "libvirtd)   -- service(self.ssh_host(), \"libvirtd\", \"restart\"",
        "libvirtd)   -- service(self.ssh_host(), \"libvirtd\", \"status\"",
        "liveimg",
        "localdomain",
        "localectl",
        "localedef",
        "localinstall",
        "localinstall)  -- cmd = \"yum -y localinstall {0}\".format(repo",
        "loginuid",
        "loopnum",
        "loopnum)    -- start(exp_send=1, exp_loopnum=1",
        "looptime",
        "menuentry",
        "menuentry)    -- host, desc=\"update grub menuentry\"",
        "migrateconfiguration",
        "migrateconfiguration) -- info(\">>>step3: run migrateconfiguration.py script\"",
        "mkconfig",
        "mkconfig)     -- ssh_host, desc=\"grub2-mkconfig\"",
        "mkimage",
        "mknod",
        "mktemp",
        "msdos",
        "multiarch",
        "multiarch)  -- \"Start to provision multiarch host\"",
        "multiarch)  -- trigger-brew\", \"trigger-multiarch\"",
        "ncat",
        "ncat)       -- yum install nmap nmap-ncat\", ssh",
        "nfsversion",
        "nics",
        "nics)                    -- FailException(f\"Failed to get nics info of {guest}\"",
        "nmap",
        "nmap)       -- self.nmap_pkg_install(ssh",
        "nmap)       -- self.pkg_check(ssh, \"nmap\"",
        "nmcli",
        "noarch",
        "noarch)     -- virtwho_build.split(\".noarch\"",
        "nodeps)     -- cmd = \"rpm -e {0} --nodeps\".format(package",
        "nodocs",
        "nosetests",
        "nrepl",
        "nutanix",
        "ocation)    -- url = line.split(\"ocation:\")[1].strip(",
        "oneshot",
        "oneshot)    -- Run virt-who with \"oneshot=False\"'",
        "oneshot)    -- def test_virtwho_oneshot(self",
        "oneshot)    -- exp_send, exp_loopnum, oneshot, exp_error, event",
        "oneshot)    -- info(\">>>step: run with oneshot value is null\"",
        "oneshot)    -- option_update_value(\"oneshot\", \"\", virtwho_conf",
        "oneshot)    -- self.vw_option_enable(\"oneshot\", virtwho_conf",
        "oneshot)    -- start(cmd, exp_send=1, oneshot=False",
        "oneshot)    -- vw_start(exp_send=1, oneshot=False",
        "oneshot)    -- vw_start(exp_send=1, oneshot=True",
        "onestho)    -- Run virt-who with \"onestho=True\"'",
        "openscap",
        "opiton",
        "ovirt",
        "ovirt)      -- hypervisor_server.rstrip(\"/ovirt-engine\"",
        "ovirt)      -- hypervisor_server.split(\"ovirt-engine\")[0].strip(",
        "ovirt)      -- virt-who for rhevm with ovirt-engine\"",
        "ovirt)      -- virt-who for rhevm with ovirt-engine/\"",
        "ovirt)      -- who for rhevm without /ovirt-engine\"",
        "parms",
        "pexpect",
        "plannedin",
        "polarion",
        "polarion)   -- # def polarion_testrun_id(",
        "polarion)   -- def polarion_testrun_id(",
        "polarion)   -- import_url = reader.get(\"polarion\", \"import_url\"",
        "polarion)   -- password = reader.get(\"polarion\", \"password\"",
        "polarion)   -- self.polarion = SetPolarion(",
        "polarion)   -- testrun_url = reader.get(\"polarion\", \"testrun_url\"",
        "polarion)   -- username = reader.get(\"polarion\", \"username\"",
        "prettyxml",
        "propertie",
        "provsion)      -- runcmd_beaker(cmd, desc=\"provsion host from beaker\"",
        "ptmx",
        "puppetca",
        "putdir",
        "putenv)     -- os.putenv(name, value",
        "putfile",
        "putfile)    -- self.paramiko_putfile(self.ssh_host(",
        "pydevproject",
        "qcow",
        "rebuilddb",
        "reconfig",
        "releasever",
        "reobj",
        "reobj)      -- match = reobj.search(url",
        "reparse",
        "reparse)    -- reparse.toprettyxml(",
        "reqs",
        "reregister",
        "reservesys",
        "retcode",
        "retcode)    -- Retcode: {0}\\n\".format(retcode)",
        "retcode)    -- return retcode, stdout.strip(",
        "rhev",
        "rhev)       -- raise FailException(\"no rhev iso url\"",
        "rhev)       -- reader.get(\"trigger\", \"rhev_iso\"",
        "rhevh",
        "rhevm",
        "rhevm)      -- def setup_rhevm(",
        "rhevm)      -- hypervisor_type in (\"esx\", \"rhevm\"",
        "rhevm)      -- hypervisor_type in (\"esx\", \"rhevm\", \"ahv\"",
        "rhevm)      -- hypervisor_type in (\"rhevm\", \"xen\", \"hyperv\"",
        "rhevm)      -- hypervisor_type\") in (\"esx\", \"rhevm\", \"ahv\"",
        "rhevm)      -- libvirt-remote', 'xen', 'rhevm', 'kubevirt'",
        "rhevm)      -- reader.get(\"stage\", \"rhevm_user\"",
        "rhevm)      -- remote_modes.append(\"rhevm\"",
        "rhevm)      -- step1: run virt-who for rhevm with ovirt-engine\"",
        "rhscl",
        "rhsm",
        "rhsm)       -- *\\(\"(.*?)\" mode\\)', rhsm_output",
        "rhsm)       -- , proxy_port, \"/etc/rhsm/rhsm.conf\"",
        "rhsm)       -- Failed to find /var/log/rhsm/virtwho* files\"",
        "rhsm)       -- Run virt-who to check 'rhsm.connection' info\"",
        "rhsm)       -- Succeeded to find virtwho.rhsm_log file\"",
        "rhsm)       -- async_log(self, data, rhsm_output",
        "rhsm)       -- being sent to '(.*?)'\", rhsm_output",
        "rhsm)       -- check how many modes in rhsm.log\"",
        "rhsm)       -- def rhsm_backup(self, ssh",
        "rhsm)       -- def test_vw_rhsm_options(self",
        "rhsm)       -- disable(\"hostname\", \"/etc/rhsm/rhsm.conf\"",
        "rhsm)       -- disable(\"port\", \"/etc/rhsm/rhsm.conf\"",
        "rhsm)       -- disable(\"prefix\", \"/etc/rhsm/rhsm.conf\"",
        "rhsm)       -- guest association in rhsm.log\"",
        "rhsm)       -- host(",
        "rhsm)       -- hostname\", \"/etc/rhsm/rhsm.conf\"",
        "rhsm)       -- mapping_info = rex.findall(rhsm_output",
        "rhsm)       -- prefix\", \"/etc/rhsm/rhsm.conf\"",
        "rhsm)       -- self.msg_validation(rhsm_output, error_msg",
        "rhsm)       -- self.msg_validation(rhsm_output, msg_list",
        "rhsm)       -- self.rhsm_backup(ssh",
        "rhsm)       -- self.rhsm_recovery(ssh",
        "rhsm)       -- self.vw_msg_search(rhsm_output, error_msg",
        "rhsm)       -- self.vw_msg_search(rhsm_output, msg",
        "rhsm)       -- self.vw_msg_search(rhsm_output, msg2",
        "rhsm)       -- self.vw_msg_search(rhsm_output, war_msg",
        "rhsm)       -- service to check the rhsm.log\"",
        "rhsm)       -- the prompt in /var/log/rhsm.log\"",
        "rhsm)       -- to run json.loads for rhsm.log\"",
        "rhsm)       -- without rhsm_username and rhsm_password\"",
        "rhsmcertd",
        "rhsmcertd)  -- service(self.ssh_host(), \"rhsmcertd\", \"restart\"",
        "rhsmlog",
        "rhts)       -- randint(1, 10000)",
        "rootpw",
        "rpcbind",
        "rpmdb",
        "rpms",
        "rubygem",
        "runcmd",
        "runcmd)        -- ret, output = self.runcmd(cmd, system",
        "runcmd)     -- _, result = self.runcmd(cmd, ssh_register",
        "runcmd)     -- provision.runcmd(cmd, ssh_sat",
        "runcmd)     -- ret, output = self.runcmd(cmd, ssh",
        "runcmd)     -- ret, output = self.runcmd(cmd, ssh_host",
        "runcmd)     -- ret, result = self.runcmd(cmd, ssh_sat",
        "sattools",
        "servername",
        "serverpath",
        "serverurl",
        "serverurl)  -- format(deploy.register.serverurl",
        "serverurl)  -- reader.get(\"register\", \"serverurl\"",
        "servie",
        "setenforce",
        "setopt",
        "shellrc",
        "skus",
        "splashimage)  -- \"splashimage=(hd0,0",
        "squashfs",
        "squashfs)      -- desc=\"rpm2cpio to get squashfs.img\"",
        "squashfs)      -- ssh_nfs, desc=\"copy squashfs.img\"",
        "sshkey",
        "subscritons) -- error(\"failed to get subscritons info\"",
        "subsystemteam",
        "sysconf",
        "sysconf)    -- DEBUG\", \"0\", filename=sysconf_file",
        "sysconf)    -- DEBUG\", \"1\", filename=sysconf_file",
        "sysconf)    -- ONE_SHOT\", filename=sysconf_file",
        "sysconf)    -- SHOT\", \"0\", filename=sysconf_file",
        "sysconf)    -- SHOT\", \"1\", filename=sysconf_file",
        "sysconf)    -- VIRTWHO_DEBUG\", filename=sysconf_file",
        "sysconf)    -- cmd = \"cat {}\".format(sysconf_file",
        "sysconf)    -- option_tested, filename=sysconf_file",
        "sysconfig",
        "testrun",
        "testrun)    -- # def polarion_testrun_id(",
        "testrun)    -- reader.get(\"polarion\", \"testrun_url\"",
        "testsuites)    -- update_file(xml_file, \"</testsuites>\", data",
        "testsuites) -- xml_init(xml_file, \"testsuites\"",
        "thinp",
        "tmpdir)     -- target=$(mktemp -d --tmpdir $(basename $0",
        "tsflags",
        "unasync",
        "unattach",
        "unattach)   -- pool is revoked after unattach physical sku\"",
        "unattach)   -- self.system_sku_unattach(self.ssh_guest()",
        "unattach)   -- self.system_sku_unattach(self.ssh_host()",
        "unattach)   -- server type for web unattach\"",
        "uncompress)    -- FailException(\"Failed to uncompress guest image\"",
        "unlimit",
        "unlimit)    -- \">>> attach virtual unlimit pool for guest\"",
        "unlimit)    -- reader.get(\"manifest\", \"unlimit\"",
        "unsupport",
        "unsupport)  -- Bug(Step3",
        "urandom",
        "uuidgen",
        "uuidgen)    -- output = self.runcmd(\"uuidgen | tr a-z A-Z\", ssh",
        "valide",
        "vdsm",
        "vdsm)       -- hypervisor_type in (\"rhevm\", \"vdsm\"",
        "vdsm)       -- in (\"libvirt-local\", \"vdsm\"",
        "vdsm)       -- in (\"libvirt-local\", \"vdsm\", \"kubevirt\"",
        "vdsm)       -- in (\"libvirt-local\", \"vdsm\", \"xen\"",
        "vdsm)       -- local_modes.append(\"vdsm\"",
        "vdsm)       -- reader.get(\"stage\", \"vdsm_user\"",
        "vdsm)       -- skip(\"libvirt-local or vdsm\"",
        "vhdx",
        "vhdx)          -- , 'C:\\hyperv_img\\%s.vhdx'",
        "virsh",
        "virt",
        "virt)        -- uninstall(self.ssh_host(), \"virt-who\"",
        "virt)       -- \"Start to provision virt-who docker hosts\"",
        "virt)       -- check(self.ssh_host(), \"virt-who\"",
        "virt)       -- enable(\"[global]\", \"/etc/virt-who.conf\"",
        "virt)       -- global]\", filename=\"/etc/virt-who.conf\"",
        "virt)       -- info(\">>>step1: run virt-who-password\"",
        "virt)       -- info(self.ssh_host(), \"virt-who\"",
        "virt)       -- uninstall(self.ssh_host(), \"virt-who\"",
        "virtlogd",
        "virtualmachineinstances",
        "virtwho",
        "virtwho)    -- [global]\", filename=virtwho_conf",
        "virtwho)    -- cls(",
        "virtwho)    -- debug\", \"True\", filename=virtwho_conf",
        "virtwho)    -- def test_virtwho_debug(self",
        "virtwho)    -- def test_virtwho_hypervisor_id(self",
        "virtwho)    -- def test_virtwho_interval(self",
        "virtwho)    -- def test_virtwho_oneshot(self",
        "virtwho)    -- enable(\"[defaults]\", virtwho_conf",
        "virtwho)    -- enable(\"debug\", filename=virtwho_conf",
        "virtwho)    -- enable(\"hypervisor_id\", virtwho_conf",
        "virtwho)    -- error(\"Failed to find virtwho.destination file\"",
        "virtwho)    -- info(\"Succeeded to find virtwho.destination file\"",
        "virtwho)    -- info(\"Succeeded to find virtwho.main file\"",
        "virtwho)    -- init(\"satellite-host-virtwho\", ssh_sat",
        "virtwho)    -- option_enable(\"[global]\", virtwho_conf",
        "virtwho)    -- option_enable(\"debug\", virtwho_conf",
        "virtwho)    -- option_enable(\"print_\", virtwho_conf",
        "virtwho)    -- reader.get(\"trigger\", \"virtwho_upstream\"",
        "virtwho)    -- runcmd(\"ls /var/log/rhsm/virtwho*\", self.ssh_host()",
        "virtwho)    -- scheduler(register_servers, virtwho_hosts, guests",
        "virtwho)    -- to find /var/log/rhsm/virtwho* files\"",
        "virtwho)    -- update_value(\"debug\", \"\", virtwho_conf",
        "virtwho)    -- value(\"debug\", \"True\", virtwho_conf",
        "virtwho)    -- value(\"print_\", \"false\", virtwho_conf",
        "virtwho)    -- vcenter cluster name to: virtwho/test\"",
        "virtwho)    -- vw_etc_d_mode_create(\"virtwho-config\", conf_file",
        "virtwhoconfig",
        "virtwo",
        "vitual)     -- \"Failed to check, vitual sku({0}",
        "vitual)     -- Succeeded to check, vitual sku({0}",
        "vmfs",
        "vmlinux)      -- host, desc=\"download vmlinux file\"",
        "webui",
        "webui)      -- delete hypervisor from webui\"",
        "webui)      -- delete virt-who host from webui\"",
        "webui)      -- guest association in webui\"",
        "webui)      -- host/hypervisor from webui\"",
        "withou",
        "wpoteat",
        "xunit",
        "yuefliu",
        "yumconf",
        "zerombr",
        "zoneinfo",
        "zxvf"
    ]
}